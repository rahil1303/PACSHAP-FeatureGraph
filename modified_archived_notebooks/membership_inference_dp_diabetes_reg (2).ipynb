{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXZT5iLnquZq"
      },
      "source": [
        "# Using ML anonymization to defend against membership inference attacks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmincMjcquZs"
      },
      "source": [
        "In this tutorial we will show how to anonymize models using the ML anonymization module.\n",
        "\n",
        "We will demonstrate running inference attacks both on a vanilla model, and then on an anonymized version of the model. We will run a black-box membership inference attack using ART's inference module (https://github.com/Trusted-AI/adversarial-robustness-toolbox/tree/main/art/attacks/inference).\n",
        "\n",
        "This will be demonstarted using the Adult dataset (original dataset can be found here: https://archive.ics.uci.edu/ml/datasets/nursery).\n",
        "\n",
        "For simplicity, we used only the numerical features in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-ZQHRRJquZs"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH95GQFcquZt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = load_diabetes()\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=0.5, random_state=14)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ai-privacy-toolkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2wmDELcq62B",
        "outputId": "60256e7b-bd8d-49f4-f62c-e67707206a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ai-privacy-toolkit\n",
            "  Downloading ai_privacy_toolkit-0.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Downloading ai_privacy_toolkit-0.2.1-py3-none-any.whl (57 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/57.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ai-privacy-toolkit\n",
            "Successfully installed ai-privacy-toolkit-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install adversarial-robustness-toolbox"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xw42D2pq_cg",
        "outputId": "6edfda35-1485-4041-e3bd-96b367db1894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adversarial-robustness-toolbox\n",
            "  Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.5.0)\n",
            "Downloading adversarial_robustness_toolbox-1.19.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: adversarial-robustness-toolbox\n",
            "Successfully installed adversarial-robustness-toolbox-1.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJcNDMcNquZu"
      },
      "source": [
        "## Train linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ-VnB5vquZu",
        "outputId": "0171fc9c-d638-4a90-e232-6f60fc11c25e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Base model accuracy (R2 score):  0.5080563960651392\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from art.estimators.regression.scikitlearn import ScikitlearnRegressor\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "art_classifier = ScikitlearnRegressor(model)\n",
        "\n",
        "print('Base model accuracy (R2 score): ', model.score(X_test, y_test))\n",
        "\n",
        "x_train_predictions = art_classifier.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR3ewSPfquZv"
      },
      "source": [
        "## Attack\n",
        "The black-box attack basically trains an additional classifier (called the attack model) to predict the membership status of a sample.\n",
        "#### Train attack model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFWMfYiUquZv",
        "outputId": "b0539d0b-4fdc-4478-82d3-31a51b44467f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4864864864864865\n"
          ]
        }
      ],
      "source": [
        "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
        "\n",
        "# attack_model_type can be nn (neural network), rf (random forest) or gb (gradient boosting)\n",
        "bb_attack = MembershipInferenceBlackBox(art_classifier, attack_model_type='nn', input_type='loss')\n",
        "\n",
        "# use half of each dataset for training the attack\n",
        "attack_train_ratio = 0.5\n",
        "attack_train_size = int(len(X_train) * attack_train_ratio)\n",
        "attack_test_size = int(len(X_test) * attack_train_ratio)\n",
        "\n",
        "# train attack model\n",
        "bb_attack.fit(X_train[:attack_train_size], y_train[:attack_train_size],\n",
        "              X_test[:attack_test_size], y_test[:attack_test_size])\n",
        "\n",
        "# get inferred values for remaining half\n",
        "inferred_train_bb = bb_attack.infer(X_train[attack_train_size:], y_train[attack_train_size:])\n",
        "inferred_test_bb = bb_attack.infer(X_test[attack_test_size:], y_test[attack_test_size:])\n",
        "# check accuracy\n",
        "train_acc = np.sum(inferred_train_bb) / len(inferred_train_bb)\n",
        "test_acc = 1 - (np.sum(inferred_test_bb) / len(inferred_test_bb))\n",
        "acc = (train_acc * len(inferred_train_bb) + test_acc * len(inferred_test_bb)) / (len(inferred_train_bb) + len(inferred_test_bb))\n",
        "print(acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wesonDFPquZw"
      },
      "source": [
        "This means that for 52% of the data, membership is inferred correctly using this attack.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huf3XvZNquZw",
        "outputId": "dc7c0bc0-5ca4-4c90-bd56-36c7ddb2b97f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique rows in original data:  221\n",
            "k values:  [5, 10, 20, 50, 75]\n",
            "unique rows: [34, 19, 8, 4, 2]\n",
            "model accuracy: [0.42383737384688003, 0.33957806593363826, -0.8038217381498651, 0.38276683002205614, 0.2961952368812176]\n",
            "attack accuracy: [0.5090090090090089, 0.536036036036036, 0.5180180180180181, 0.4954954954954955, 0.5180180180180181]\n"
          ]
        }
      ],
      "source": [
        "from apt.utils.datasets import ArrayDataset\n",
        "from apt.anonymization import Anonymize\n",
        "k_values=[5, 10, 20, 50, 75]\n",
        "model_accuracy = []\n",
        "attack_accuracy = []\n",
        "unique_values = []\n",
        "\n",
        "# QI = all\n",
        "QI = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "print('unique rows in original data: ', len(np.unique(X_train, axis=0)))\n",
        "\n",
        "for k in k_values:\n",
        "    anonymizer = Anonymize(k, QI, is_regression=True)\n",
        "    anon = anonymizer.anonymize(ArrayDataset(X_train, x_train_predictions))\n",
        "    unique_values.append(len(np.unique(anon, axis=0)))\n",
        "\n",
        "    anon_model = LinearRegression()\n",
        "    anon_model.fit(anon, y_train)\n",
        "\n",
        "    anon_art_classifier = ScikitlearnRegressor(anon_model)\n",
        "\n",
        "    model_accuracy.append(anon_model.score(X_test, y_test))\n",
        "\n",
        "    anon_bb_attack = MembershipInferenceBlackBox(anon_art_classifier, attack_model_type='rf', input_type='loss')\n",
        "\n",
        "    # train attack model\n",
        "    anon_bb_attack.fit(X_train[:attack_train_size], y_train[:attack_train_size],\n",
        "                       X_test[:attack_test_size], y_test[:attack_test_size])\n",
        "\n",
        "    # get inferred values\n",
        "    anon_inferred_train_bb = anon_bb_attack.infer(X_train[attack_train_size:], y_train[attack_train_size:])\n",
        "    anon_inferred_test_bb = anon_bb_attack.infer(X_test[attack_test_size:], y_test[attack_test_size:])\n",
        "    # check accuracy\n",
        "    anon_train_acc = np.sum(anon_inferred_train_bb) / len(anon_inferred_train_bb)\n",
        "    anon_test_acc = 1 - (np.sum(anon_inferred_test_bb) / len(anon_inferred_test_bb))\n",
        "    anon_acc = (anon_train_acc * len(anon_inferred_train_bb) + anon_test_acc * len(anon_inferred_test_bb)) / (len(anon_inferred_train_bb) + len(anon_inferred_test_bb))\n",
        "    attack_accuracy.append(anon_acc)\n",
        "\n",
        "print('k values: ', k_values)\n",
        "print('unique rows:', unique_values)\n",
        "print('model accuracy:', model_accuracy)\n",
        "print('attack accuracy:', attack_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJpIfF6oquZx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}