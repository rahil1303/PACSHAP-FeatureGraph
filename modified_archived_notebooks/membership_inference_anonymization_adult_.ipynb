{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# For reproducibility\n",
        "np.random.seed(42)\n",
        "import random\n",
        "random.seed(42)\n"
      ],
      "metadata": {
        "id": "Al5ulTaf5jbK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tedea39X4TZ6",
        "outputId": "0da61dc6-dba3-4c1e-bc8a-f14762abe22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adversarial-robustness-toolbox in /usr/local/lib/python3.11/dist-packages (1.19.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (75.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from adversarial-robustness-toolbox) (4.67.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.2->adversarial-robustness-toolbox) (3.5.0)\n",
            "Requirement already satisfied: ai-privacy-toolkit in /usr/local/lib/python3.11/dist-packages (0.2.1)\n",
            "--2025-02-23 22:48:22--  https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘../datasets/adult.data.7’\n",
            "\n",
            "adult.data.7            [          <=>       ]   3.79M  99.8KB/s    in 45s     \n",
            "\n",
            "2025-02-23 22:49:08 (86.8 KB/s) - ‘../datasets/adult.data.7’ saved [3974305]\n",
            "\n",
            "Base model accuracy: 0.8172884999232305\n",
            "Attack accuracy on base model: 0.8143234445058657\n",
            "[[34 13  0  0 45]\n",
            " [42 13  0  0 45]\n",
            " [20  9  0  0 24]\n",
            " ...\n",
            " [50  9  0  0 50]\n",
            " [25 13  0  0 50]\n",
            " [30  6  0  0 40]]\n",
            "Anonymized model accuracy: 0.8340242591739597\n",
            "Attack accuracy on anonymized model: 0.7978011178674529\n",
            "without anonymization: (0.8124726613759921, 0.9983108108108109)\n",
            "with anonymization: (0.7998521074685728, 0.9966216216216216)\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install adversarial-robustness-toolbox\n",
        "!pip install ai-privacy-toolkit\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from art.estimators.classification.scikitlearn import ScikitlearnDecisionTreeClassifier\n",
        "from art.attacks.inference.membership_inference import MembershipInferenceBlackBox\n",
        "from apt.utils.datasets import ArrayDataset\n",
        "from apt.anonymization import Anonymize\n",
        "\n",
        "# Download and load dataset\n",
        "!mkdir -p ../datasets\n",
        "!wget -P ../datasets https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n",
        "\n",
        "data = pd.read_csv(\"../datasets/adult.data\", header=None, skipinitialspace=True)\n",
        "\n",
        "# Numerical features only\n",
        "num_features = [0, 4, 10, 11, 12]\n",
        "X = data.iloc[:, num_features].values\n",
        "y = data.iloc[:, 14].values\n",
        "\n",
        "y = np.array([label.strip() for label in y])\n",
        "y = np.where(y == \"<=50K\", 0, 1)\n",
        "\n",
        "# Split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "y_train = y_train.astype(int)\n",
        "y_test = y_test.astype(int)\n",
        "\n",
        "# Train Decision Tree\n",
        "model = DecisionTreeClassifier()\n",
        "model.fit(x_train, y_train)\n",
        "art_classifier = ScikitlearnDecisionTreeClassifier(model)\n",
        "print('Base model accuracy:', model.score(x_test, y_test))\n",
        "\n",
        "# Membership Inference Attack on Base Model\n",
        "bb_attack = MembershipInferenceBlackBox(art_classifier, attack_model_type='rf')\n",
        "attack_train_ratio = 0.5\n",
        "attack_train_size = int(len(x_train) * attack_train_ratio)\n",
        "attack_test_size = int(len(x_test) * attack_train_ratio)\n",
        "\n",
        "bb_attack.fit(x_train[:attack_train_size], y_train[:attack_train_size],\n",
        "              x_test[:attack_test_size], y_test[:attack_test_size])\n",
        "\n",
        "inferred_train_bb = bb_attack.infer(x_train[attack_train_size:], y_train[attack_train_size:])\n",
        "inferred_test_bb = bb_attack.infer(x_test[attack_test_size:], y_test[attack_test_size:])\n",
        "\n",
        "train_acc = np.sum(inferred_train_bb) / len(inferred_train_bb)\n",
        "test_acc = 1 - (np.sum(inferred_test_bb) / len(inferred_test_bb))\n",
        "acc = (train_acc * len(inferred_train_bb) + test_acc * len(inferred_test_bb)) / (len(inferred_train_bb) + len(inferred_test_bb))\n",
        "print(\"Attack accuracy on base model:\", acc)\n",
        "\n",
        "# Anonymize data\n",
        "x_train_predictions = np.array([np.argmax(arr) for arr in art_classifier.predict(x_train)])\n",
        "QI = [0, 1, 2, 4]\n",
        "anonymizer = Anonymize(100, QI)\n",
        "anon = anonymizer.anonymize(ArrayDataset(x_train, x_train_predictions))\n",
        "print(anon)\n",
        "\n",
        "# number of distinct rows in original data\n",
        "len(np.unique(x_train, axis=0))\n",
        "\n",
        "# number of distinct rows in anonymized data\n",
        "len(np.unique(anon, axis=0))\n",
        "\n",
        "# Train on Anonymized Data\n",
        "anon_model = DecisionTreeClassifier()\n",
        "anon_model.fit(anon, y_train)\n",
        "anon_art_classifier = ScikitlearnDecisionTreeClassifier(anon_model)\n",
        "print('Anonymized model accuracy:', anon_model.score(x_test, y_test))\n",
        "\n",
        "# Membership Inference Attack on Anonymized Model\n",
        "anon_bb_attack = MembershipInferenceBlackBox(anon_art_classifier, attack_model_type='rf')\n",
        "anon_bb_attack.fit(x_train[:attack_train_size], y_train[:attack_train_size],\n",
        "                   x_test[:attack_test_size], y_test[:attack_test_size])\n",
        "\n",
        "anon_inferred_train_bb = anon_bb_attack.infer(x_train[attack_train_size:], y_train[attack_train_size:])\n",
        "anon_inferred_test_bb = anon_bb_attack.infer(x_test[attack_test_size:], y_test[attack_test_size:])\n",
        "\n",
        "anon_train_acc = np.sum(anon_inferred_train_bb) / len(anon_inferred_train_bb)\n",
        "anon_test_acc = 1 - (np.sum(anon_inferred_test_bb) / len(anon_inferred_test_bb))\n",
        "anon_acc = (anon_train_acc * len(anon_inferred_train_bb) + anon_test_acc * len(anon_inferred_test_bb)) / (len(anon_inferred_train_bb) + len(anon_inferred_test_bb))\n",
        "print(\"Attack accuracy on anonymized model:\", anon_acc)\n",
        "\n",
        "def calc_precision_recall(predicted, actual, positive_value=1):\n",
        "  score = 0 # both predicted and actual are positive\n",
        "  num_positive_predicted = 0 # predicted positive\n",
        "  num_positive_actual = 0 # actual positive\n",
        "  for i in range(len(predicted)):\n",
        "    if predicted[i] == positive_value:\n",
        "      num_positive_predicted += 1\n",
        "    if actual[i] == positive_value:\n",
        "      num_positive_actual += 1\n",
        "    if predicted[i] == actual[i]:\n",
        "      if predicted[i] == positive_value:\n",
        "        score += 1\n",
        "  if num_positive_predicted == 0:\n",
        "     precision = 1\n",
        "  else:\n",
        "    precision = score / num_positive_predicted # the fraction of predicted “Yes” responses that are correct\n",
        "  if num_positive_actual == 0:\n",
        "    recall = 1\n",
        "  else:\n",
        "    recall = score / num_positive_actual # the fraction of “Yes” responses that are predicted correctly\n",
        "  return precision, recall\n",
        "# regular\n",
        "print('without anonymization:', calc_precision_recall(np.concatenate((inferred_train_bb, inferred_test_bb)),\n",
        "np.concatenate((np.ones(len(inferred_train_bb)), np.zeros(len(inferred_test_bb))))))\n",
        "# anon\n",
        "print('with anonymization:', calc_precision_recall(np.concatenate((anon_inferred_train_bb, anon_inferred_test_bb)),\n",
        "np.concatenate((np.ones(len(anon_inferred_train_bb)), np.zeros(len(anon_inferred_test_bb))))))\n"
      ]
    }
  ]
}